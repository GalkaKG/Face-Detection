{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52470874-79a3-48d8-91c8-b83ad0aadfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bf4ec-d70b-4e42-b6b2-3e54fbdadbd6",
   "metadata": {},
   "source": [
    "### Train a Custom Face Detection Model \n",
    "Let's train your own face detector, we can use a CNN-based model. Here i will use PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8493c2ec-d4c6-462f-b03f-5a4aadec5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_dir, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []  # This will be used if you're working with labeled data like LFW\n",
    "    # image_folder = os.path.join(image_dir, 'lfw-deepfunneled')  # Path to the folder containing images\n",
    "    \n",
    "    for root, dirs, files in os.walk(image_dir):  # Traverse through subfolders\n",
    "        for file in files:\n",
    "            if file.endswith(('jpg', 'jpeg', 'png')):  # Ensure you're processing image files\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    # Resize image to target size\n",
    "                    img = cv2.resize(img, target_size)\n",
    "                    # Convert image to grayscale (optional)\n",
    "                    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    images.append(img)\n",
    "                   \n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7263ba-76c6-440b-abbc-ce7b4bde521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_data_path = \"C:/Users/galin/Downloads/LFW dataset/lfw-deepfunneled\"\n",
    "lfw_images = preprocess_images(wf_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21179381-2fcc-44fd-905f-333f6df271fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a basic CNN architecture\n",
    "class FaceDetectorCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceDetectorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(64*54*54, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Binary classification: face or no face\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Prepare your data\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# Use your preprocessed datasets (wider_images/lfw_images) here\n",
    "train_dataset = datasets.ImageFolder(lfw_images, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = FaceDetectorCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Train for 10 epochs\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de5856-975e-4110-bf8e-7b429cafb70d",
   "metadata": {},
   "source": [
    "### 1. Dataset Collection\n",
    "You will need a dataset with images of faces and non-faces. Common datasets used for face detection are:\n",
    "\n",
    "Labeled Faces in the Wild (LFW)\n",
    "FDDB (Face Detection Dataset and Benchmark)\n",
    "For simplicity, let's assume you are using OpenCV's pre-trained Haar Cascade classifier for initial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55dc5e1-1cf6-4df4-8c9e-0c0409a022f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_data_path = \"C:/Users/ggeorgieva.HAEMIMONT/Downloads/LFW dataset/lfw-deepfunneled/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a033d85-c416-41b5-98e4-b744df58251c",
   "metadata": {},
   "source": [
    "### 2. Feature Extraction\n",
    "\n",
    "To train a machine learning model, you need features that represent faces. Haar Features are a good choice for this task.\n",
    "\n",
    "You can use HOG features, or you can directly use the Haar Cascade features (which OpenCV already provides as XML files) for detecting faces.\n",
    "\n",
    "The HOG features are typically used with an SVM classifier, which could work well without using deep learning.\n",
    "\n",
    "You can extract HOG features as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0555e99-7f13-4b61-9d89-773ac0be5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(f'{wf_data_path}/lfw-deepfunneled/Zico/Zico_0001.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Extract HOG features\n",
    "fd, hog_image = hog(gray, visualize=True, block_norm='L2-Hys')\n",
    "\n",
    "# Rescale the HOG image for display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow('HOG Image', hog_image_rescaled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff5dc5-9bdb-499e-8ece-6264659572f8",
   "metadata": {},
   "source": [
    "### 3. Train a Support Vector Machine (SVM) Classifier\n",
    "You can use SVM to classify whether the extracted features correspond to a face or not.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498be64b-2159-4c1f-a67f-91842d45a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X contains the extracted features (HOG or others) and y contains labels (1 for face, 0 for non-face)\n",
    "X = np.array([...])  # Features\n",
    "y = np.array([...])  # Labels (1 for face, 0 for non-face)\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "clf = SVC(kernel='linear')  # You can experiment with other kernels like 'rbf'\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ff644-1f2c-4d13-8ac4-540dbec684e5",
   "metadata": {},
   "source": [
    "You can experiment with different classifiers like Random Forest, k-NN, or Logistic Regression, but SVM tends to work well for image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915feb77-3d81-4f54-bf5c-e1c227e3e11a",
   "metadata": {},
   "source": [
    "### 4. Integrating the Model for Face Detection\n",
    "Once you have a trained model, you can use OpenCV to detect faces in a live video feed or an image. You can use OpenCV's Haar Cascade or your SVM model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b3aa0-e384-4d2f-a6f9-62e1c31ed9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trained model (if using an SVM)\n",
    "# clf = load_trained_model()  # Example of loading an SVM model\n",
    "\n",
    "# Initialize OpenCVâ€™s Haar Cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('test_image.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Draw rectangles around faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Show the image with detected faces\n",
    "cv2.imshow('Face Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
